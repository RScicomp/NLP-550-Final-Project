{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_excel(\"people.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['Biography'])] #remove all rows that do not have a biography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "firstGood = int(0.3*total) #1 if the founder is in the top 30 percent, 0 otherwise\n",
    "labels = [\"1\" for i in range(firstGood)] + [\"0\" for i in range(total-firstGood)]\n",
    "df['labels'] = labels #add labels as a new column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle the rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = [bio.strip() for bio in df['Biography'].tolist()] #remove leading and ending white spaces\n",
    "labels = df['labels'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer() #we want to stem the words\n",
    "theBios = []\n",
    "\n",
    "for i in range(0,len(bios)):\n",
    "    bioWords = bios[i].split()\n",
    "    bioWordsToUse = []\n",
    "    for i in range(0,len(bioWords)): #go through each word in a bio\n",
    "        bioWords[i] = re.sub(r'\\W+', '', bioWords[i]) #only keep alphanumeric characters\n",
    "        if bioWords[i] != '':\n",
    "            bioWordsToUse.append(porter.stem(bioWords[i].lower())) #stem the words\n",
    "    theBios.append(' '.join(bioWordsToUse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\") #removing stop words\n",
    "x_Bios = vectorizer.fit_transform(theBios).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenthuransivanandan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#in order to one hot encode we must give a 2d array\n",
    "\n",
    "labels = [[labels[i]] for i in range(0,len(labels))]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(labels).toarray() #one hot encoded versions of our outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_Bios,y,test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "578/578 [==============================] - 0s 392us/step - loss: 0.6863 - accuracy: 0.6955\n",
      "Epoch 1/2\n",
      "578/578 [==============================] - 0s 398us/step - loss: 0.6853 - accuracy: 0.6990\n",
      "Epoch 2/2\n",
      "578/578 [==============================] - 0s 163us/step - loss: 0.6602 - accuracy: 0.7093\n",
      "Epoch 1/3\n",
      "578/578 [==============================] - 0s 385us/step - loss: 0.6911 - accuracy: 0.6592\n",
      "Epoch 2/3\n",
      "578/578 [==============================] - 0s 153us/step - loss: 0.6849 - accuracy: 0.7093\n",
      "Epoch 3/3\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.6780 - accuracy: 0.7093\n",
      "Epoch 1/4\n",
      "578/578 [==============================] - 0s 449us/step - loss: 0.6911 - accuracy: 0.6557\n",
      "Epoch 2/4\n",
      "578/578 [==============================] - 0s 154us/step - loss: 0.6790 - accuracy: 0.7093\n",
      "Epoch 3/4\n",
      "578/578 [==============================] - 0s 160us/step - loss: 0.6629 - accuracy: 0.7093\n",
      "Epoch 4/4\n",
      "578/578 [==============================] - 0s 152us/step - loss: 0.6407 - accuracy: 0.7093\n",
      "Epoch 1/5\n",
      "578/578 [==============================] - 0s 416us/step - loss: 0.6879 - accuracy: 0.6834\n",
      "Epoch 2/5\n",
      "578/578 [==============================] - 0s 230us/step - loss: 0.6681 - accuracy: 0.7093\n",
      "Epoch 3/5\n",
      "578/578 [==============================] - 0s 367us/step - loss: 0.6402 - accuracy: 0.7093\n",
      "Epoch 4/5\n",
      "578/578 [==============================] - 0s 185us/step - loss: 0.6031 - accuracy: 0.7093\n",
      "Epoch 5/5\n",
      "578/578 [==============================] - 0s 147us/step - loss: 0.5580 - accuracy: 0.7093\n",
      "Epoch 1/6\n",
      "578/578 [==============================] - 1s 925us/step - loss: 0.6885 - accuracy: 0.7059\n",
      "Epoch 2/6\n",
      "578/578 [==============================] - 0s 334us/step - loss: 0.6716 - accuracy: 0.7093\n",
      "Epoch 3/6\n",
      "578/578 [==============================] - 0s 433us/step - loss: 0.6466 - accuracy: 0.7093\n",
      "Epoch 4/6\n",
      "578/578 [==============================] - 0s 340us/step - loss: 0.6115 - accuracy: 0.7093\n",
      "Epoch 5/6\n",
      "578/578 [==============================] - 0s 220us/step - loss: 0.5703 - accuracy: 0.7093\n",
      "Epoch 6/6\n",
      "578/578 [==============================] - 0s 209us/step - loss: 0.5241 - accuracy: 0.70930s - loss: 0.5135 - accuracy: 0.73\n",
      "Epoch 1/7\n",
      "578/578 [==============================] - 0s 577us/step - loss: 0.6878 - accuracy: 0.6678\n",
      "Epoch 2/7\n",
      "578/578 [==============================] - 0s 186us/step - loss: 0.6662 - accuracy: 0.7093\n",
      "Epoch 3/7\n",
      "578/578 [==============================] - 0s 152us/step - loss: 0.6397 - accuracy: 0.7093\n",
      "Epoch 4/7\n",
      "578/578 [==============================] - 0s 206us/step - loss: 0.6095 - accuracy: 0.7093\n",
      "Epoch 5/7\n",
      "578/578 [==============================] - 0s 175us/step - loss: 0.5710 - accuracy: 0.7093\n",
      "Epoch 6/7\n",
      "578/578 [==============================] - 0s 157us/step - loss: 0.5217 - accuracy: 0.7093\n",
      "Epoch 7/7\n",
      "578/578 [==============================] - 0s 218us/step - loss: 0.4557 - accuracy: 0.7197\n",
      "Epoch 1/8\n",
      "578/578 [==============================] - 0s 414us/step - loss: 0.6860 - accuracy: 0.6955\n",
      "Epoch 2/8\n",
      "578/578 [==============================] - 0s 126us/step - loss: 0.6632 - accuracy: 0.7093\n",
      "Epoch 3/8\n",
      "578/578 [==============================] - 0s 139us/step - loss: 0.6370 - accuracy: 0.7093\n",
      "Epoch 4/8\n",
      "578/578 [==============================] - 0s 157us/step - loss: 0.6086 - accuracy: 0.7093\n",
      "Epoch 5/8\n",
      "578/578 [==============================] - 0s 219us/step - loss: 0.5690 - accuracy: 0.7093\n",
      "Epoch 6/8\n",
      "578/578 [==============================] - 0s 161us/step - loss: 0.5187 - accuracy: 0.7093\n",
      "Epoch 7/8\n",
      "578/578 [==============================] - 0s 155us/step - loss: 0.4653 - accuracy: 0.7093\n",
      "Epoch 8/8\n",
      "578/578 [==============================] - 0s 160us/step - loss: 0.4004 - accuracy: 0.7093\n",
      "Epoch 1/9\n",
      "578/578 [==============================] - 0s 419us/step - loss: 0.6846 - accuracy: 0.6920\n",
      "Epoch 2/9\n",
      "578/578 [==============================] - 0s 153us/step - loss: 0.6610 - accuracy: 0.7093\n",
      "Epoch 3/9\n",
      "578/578 [==============================] - 0s 161us/step - loss: 0.6256 - accuracy: 0.7093\n",
      "Epoch 4/9\n",
      "578/578 [==============================] - 0s 140us/step - loss: 0.5862 - accuracy: 0.7093\n",
      "Epoch 5/9\n",
      "578/578 [==============================] - 0s 134us/step - loss: 0.5401 - accuracy: 0.7093\n",
      "Epoch 6/9\n",
      "578/578 [==============================] - 0s 160us/step - loss: 0.4855 - accuracy: 0.7093\n",
      "Epoch 7/9\n",
      "578/578 [==============================] - 0s 177us/step - loss: 0.4106 - accuracy: 0.7197\n",
      "Epoch 8/9\n",
      "578/578 [==============================] - 0s 181us/step - loss: 0.3120 - accuracy: 0.8512\n",
      "Epoch 9/9\n",
      "578/578 [==============================] - 0s 162us/step - loss: 0.2211 - accuracy: 0.9827\n",
      "Epoch 1/10\n",
      "578/578 [==============================] - 0s 402us/step - loss: 0.6899 - accuracy: 0.6678\n",
      "Epoch 2/10\n",
      "578/578 [==============================] - 0s 170us/step - loss: 0.6793 - accuracy: 0.7093\n",
      "Epoch 3/10\n",
      "578/578 [==============================] - 0s 166us/step - loss: 0.6645 - accuracy: 0.7093\n",
      "Epoch 4/10\n",
      "578/578 [==============================] - 0s 150us/step - loss: 0.6430 - accuracy: 0.7093\n",
      "Epoch 5/10\n",
      "578/578 [==============================] - 0s 156us/step - loss: 0.6135 - accuracy: 0.7093\n",
      "Epoch 6/10\n",
      "578/578 [==============================] - 0s 155us/step - loss: 0.5766 - accuracy: 0.7093\n",
      "Epoch 7/10\n",
      "578/578 [==============================] - 0s 162us/step - loss: 0.5248 - accuracy: 0.7093\n",
      "Epoch 8/10\n",
      "578/578 [==============================] - 0s 153us/step - loss: 0.4623 - accuracy: 0.7093\n",
      "Epoch 9/10\n",
      "578/578 [==============================] - 0s 145us/step - loss: 0.3833 - accuracy: 0.7111\n",
      "Epoch 10/10\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.2914 - accuracy: 0.8391\n",
      "Epoch 1/11\n",
      "578/578 [==============================] - 0s 440us/step - loss: 0.6875 - accuracy: 0.6920\n",
      "Epoch 2/11\n",
      "578/578 [==============================] - 0s 141us/step - loss: 0.6719 - accuracy: 0.7093\n",
      "Epoch 3/11\n",
      "578/578 [==============================] - 0s 145us/step - loss: 0.6502 - accuracy: 0.7093\n",
      "Epoch 4/11\n",
      "578/578 [==============================] - 0s 154us/step - loss: 0.6194 - accuracy: 0.7093\n",
      "Epoch 5/11\n",
      "578/578 [==============================] - 0s 154us/step - loss: 0.5808 - accuracy: 0.7093\n",
      "Epoch 6/11\n",
      "578/578 [==============================] - 0s 140us/step - loss: 0.5377 - accuracy: 0.7093\n",
      "Epoch 7/11\n",
      "578/578 [==============================] - 0s 143us/step - loss: 0.4934 - accuracy: 0.7093\n",
      "Epoch 8/11\n",
      "578/578 [==============================] - 0s 155us/step - loss: 0.4376 - accuracy: 0.7093\n",
      "Epoch 9/11\n",
      "578/578 [==============================] - 0s 142us/step - loss: 0.3709 - accuracy: 0.7093\n",
      "Epoch 10/11\n",
      "578/578 [==============================] - 0s 141us/step - loss: 0.3051 - accuracy: 0.7163\n",
      "Epoch 11/11\n",
      "578/578 [==============================] - 0s 136us/step - loss: 0.2450 - accuracy: 0.9325\n",
      "Epoch 1/12\n",
      "578/578 [==============================] - 0s 376us/step - loss: 0.6755 - accuracy: 0.7093\n",
      "Epoch 2/12\n",
      "578/578 [==============================] - 0s 138us/step - loss: 0.6275 - accuracy: 0.7093\n",
      "Epoch 3/12\n",
      "578/578 [==============================] - 0s 129us/step - loss: 0.5725 - accuracy: 0.7093\n",
      "Epoch 4/12\n",
      "578/578 [==============================] - 0s 132us/step - loss: 0.5299 - accuracy: 0.7093\n",
      "Epoch 5/12\n",
      "578/578 [==============================] - 0s 128us/step - loss: 0.4906 - accuracy: 0.7093\n",
      "Epoch 6/12\n",
      "578/578 [==============================] - 0s 137us/step - loss: 0.4332 - accuracy: 0.7093\n",
      "Epoch 7/12\n",
      "578/578 [==============================] - 0s 131us/step - loss: 0.3631 - accuracy: 0.7093\n",
      "Epoch 8/12\n",
      "578/578 [==============================] - 0s 135us/step - loss: 0.2993 - accuracy: 0.7093\n",
      "Epoch 9/12\n",
      "578/578 [==============================] - 0s 135us/step - loss: 0.2503 - accuracy: 0.7128\n",
      "Epoch 10/12\n",
      "578/578 [==============================] - 0s 138us/step - loss: 0.2181 - accuracy: 0.9671\n",
      "Epoch 11/12\n",
      "578/578 [==============================] - 0s 140us/step - loss: 0.2003 - accuracy: 0.9931\n",
      "Epoch 12/12\n",
      "578/578 [==============================] - 0s 132us/step - loss: 0.1888 - accuracy: 1.0000\n",
      "Epoch 1/13\n",
      "578/578 [==============================] - 0s 375us/step - loss: 0.6781 - accuracy: 0.7024\n",
      "Epoch 2/13\n",
      "578/578 [==============================] - 0s 140us/step - loss: 0.6389 - accuracy: 0.7093\n",
      "Epoch 3/13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578/578 [==============================] - 0s 146us/step - loss: 0.5960 - accuracy: 0.7093\n",
      "Epoch 4/13\n",
      "578/578 [==============================] - 0s 136us/step - loss: 0.5502 - accuracy: 0.7093\n",
      "Epoch 5/13\n",
      "578/578 [==============================] - 0s 130us/step - loss: 0.4941 - accuracy: 0.7093\n",
      "Epoch 6/13\n",
      "578/578 [==============================] - 0s 133us/step - loss: 0.4246 - accuracy: 0.7093\n",
      "Epoch 7/13\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.3500 - accuracy: 0.7093\n",
      "Epoch 8/13\n",
      "578/578 [==============================] - 0s 141us/step - loss: 0.2841 - accuracy: 0.7353\n",
      "Epoch 9/13\n",
      "578/578 [==============================] - 0s 144us/step - loss: 0.2329 - accuracy: 0.9533\n",
      "Epoch 10/13\n",
      "578/578 [==============================] - 0s 137us/step - loss: 0.1982 - accuracy: 0.9965\n",
      "Epoch 11/13\n",
      "578/578 [==============================] - 0s 124us/step - loss: 0.1701 - accuracy: 1.0000\n",
      "Epoch 12/13\n",
      "578/578 [==============================] - 0s 122us/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 13/13\n",
      "578/578 [==============================] - 0s 121us/step - loss: 0.1135 - accuracy: 1.0000\n",
      "Epoch 1/14\n",
      "578/578 [==============================] - 0s 388us/step - loss: 0.6900 - accuracy: 0.6626\n",
      "Epoch 2/14\n",
      "578/578 [==============================] - 0s 139us/step - loss: 0.6757 - accuracy: 0.7093\n",
      "Epoch 3/14\n",
      "578/578 [==============================] - 0s 143us/step - loss: 0.6558 - accuracy: 0.7093\n",
      "Epoch 4/14\n",
      "578/578 [==============================] - 0s 134us/step - loss: 0.6308 - accuracy: 0.7093\n",
      "Epoch 5/14\n",
      "578/578 [==============================] - 0s 122us/step - loss: 0.5973 - accuracy: 0.7093\n",
      "Epoch 6/14\n",
      "578/578 [==============================] - 0s 130us/step - loss: 0.5585 - accuracy: 0.7093\n",
      "Epoch 7/14\n",
      "578/578 [==============================] - 0s 130us/step - loss: 0.5089 - accuracy: 0.7093\n",
      "Epoch 8/14\n",
      "578/578 [==============================] - 0s 122us/step - loss: 0.4446 - accuracy: 0.7093\n",
      "Epoch 9/14\n",
      "578/578 [==============================] - 0s 134us/step - loss: 0.3686 - accuracy: 0.7837\n",
      "Epoch 10/14\n",
      "578/578 [==============================] - 0s 136us/step - loss: 0.2844 - accuracy: 0.9187\n",
      "Epoch 11/14\n",
      "578/578 [==============================] - 0s 127us/step - loss: 0.2128 - accuracy: 0.9758\n",
      "Epoch 12/14\n",
      "578/578 [==============================] - 0s 128us/step - loss: 0.1536 - accuracy: 1.0000\n",
      "Epoch 13/14\n",
      "578/578 [==============================] - 0s 124us/step - loss: 0.1084 - accuracy: 1.0000\n",
      "Epoch 14/14\n",
      "578/578 [==============================] - 0s 122us/step - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 1/15\n",
      "578/578 [==============================] - 0s 370us/step - loss: 0.6900 - accuracy: 0.6540\n",
      "Epoch 2/15\n",
      "578/578 [==============================] - 0s 150us/step - loss: 0.6781 - accuracy: 0.7093\n",
      "Epoch 3/15\n",
      "578/578 [==============================] - 0s 144us/step - loss: 0.6610 - accuracy: 0.7093\n",
      "Epoch 4/15\n",
      "578/578 [==============================] - 0s 144us/step - loss: 0.6379 - accuracy: 0.7093\n",
      "Epoch 5/15\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.6101 - accuracy: 0.7093\n",
      "Epoch 6/15\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.5685 - accuracy: 0.7093\n",
      "Epoch 7/15\n",
      "578/578 [==============================] - 0s 151us/step - loss: 0.5153 - accuracy: 0.7093\n",
      "Epoch 8/15\n",
      "578/578 [==============================] - 0s 149us/step - loss: 0.4488 - accuracy: 0.7093\n",
      "Epoch 9/15\n",
      "578/578 [==============================] - 0s 140us/step - loss: 0.3769 - accuracy: 0.7249\n",
      "Epoch 10/15\n",
      "578/578 [==============================] - 0s 147us/step - loss: 0.2948 - accuracy: 0.8737\n",
      "Epoch 11/15\n",
      "578/578 [==============================] - 0s 151us/step - loss: 0.2046 - accuracy: 0.9775\n",
      "Epoch 12/15\n",
      "578/578 [==============================] - 0s 142us/step - loss: 0.1225 - accuracy: 0.9983\n",
      "Epoch 13/15\n",
      "578/578 [==============================] - 0s 162us/step - loss: 0.0595 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "578/578 [==============================] - 0s 151us/step - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "578/578 [==============================] - 0s 161us/step - loss: 0.0129 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Lets use 1 to 10 epochs and graph the results on our test set\n",
    "epochs = [i for i in range(1,16)]\n",
    "accuracies = []\n",
    "\n",
    "for i in range(1,16):\n",
    "    #building our neural network\n",
    "    #Dependencies\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    # Neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=12609, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=i, batch_size=64) #fitting our model \n",
    "\n",
    "    y_pred = model.predict(X_test) #predicting the values from our test data\n",
    "    #Converting predictions to label\n",
    "    pred = list()\n",
    "    for i in range(len(y_pred)):\n",
    "        pred.append(np.argmax(y_pred[i])) #find what we predicted\n",
    "    #Converting one hot encoded test label to label\n",
    "    test = list()\n",
    "    for i in range(len(y_test)):\n",
    "        test.append(np.argmax(y_test[i])) #find what was suppose to be predicted\n",
    "        \n",
    "    a = accuracy_score(pred,test)*100 #get the accuracy\n",
    "    accuracies.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, accuracies, 'ro')\n",
    "#plt.axis([0, 6, 0, 20])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracies')\n",
    "plt.title(\"epochs vs accuracies\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
